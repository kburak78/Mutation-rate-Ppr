# Estimation of Mutation Rate in Plathynothrus peltifer
- - - -

This file encompasses all scripts of how I calculated the mutation rate in Plathynothrus peltifer.

The file is structured as follows:
1. [Sampling and Sequencing](#Sampling)
    1. [Sampling](#Sampling1)
    2. [Sequncing](#Seq)
    3. [Umi tools, Trimming and concatenating read data](#Umi)
2. [Alignment & Post-Alignment Processing](#Alignment)
3. [Variant Calling with GATK](#GATK)
4. [Detect de novo mutations](#Mutations)
    1. [Filter DP](#DP)
    2. [Filter GT](#GT)
    3. [Filter GQ & PL](#GQ)
    4. [Filter AD](#AD)
6. [Callable genome estimation](#CG)
7. [Calculating the mutation rate](#Mutrate)

You will also find two other files in the repository: 
'R Graphs' - the scripts to visualize the results 
'Ppr Eggs' - what I did for the additional data of two eggs 

- - - -

## 1. Sampling and Sequencing <a name="Sampling"></a>
### a. Sampling
The oribatid mites were sampled early June at the “Moorpfad” in Dahlem, Germany (50.389204, 6.568780).
- M6 -> S1 
- E6.2 -> S2
- M30 -> S3
- E30.7 -> S4
- M31 -> S5
- E31.6 -> S6
- E31. -> S7
- E31. -> S8
    
### b. Sequncing 

The DNA was send to be sequenced with Illumina Next Generation Sequencing (NovaSeq6000) with 2 additional kits -the 'NEBNext Ultra II FS DNA Library Prep Kit for Illumina' and 'NEBNext Multiplex Oligos for Illumina (Unique Dual Index UMI Adaptors DNA Set 1)'.
FastaQ files provided by Cologne's Center for Genomics.

The average reading lenght was 151. 

The raw reads are named like this and can be found in /RAID/Data/linda/Mother
153621_S1.R1_val_1.fq.gz
153621_S1.R3_val_2.fq.gz
153622_S2.R1_val_1.fq.gz
153622_S2.R3_val_2.fq.gz
153623_S3.R1_val_1.fq.gz
153623_S3.R3_val_2.fq.gz
153624_S4.R1_val_1.fq.gz
153624_S4.R3_val_2.fq.gz
153625_S5.R1_val_1.fq.gz
153625_S5.R3_val_2.fq.gz
153626_S6.R1_val_1.fq.gz
153626_S6.R3_val_2.fq.gz

Sequences provided by CCG in September and October. September ones went already through umi_tools and trimming in https://github.com/wintergoldcrest/umi_tools.

### c. Umi tools, Trimming and concatenating all Data
Trimming Illumina adapters and Umi adapters from raw reads.
To look into the script: cat /RAID/Data/linda/october/test.sh

conda activate uni_tools

    for i in A006200184_153621_S1 \
    A006200184_153622_S2 \
    A006200184_153623_S3 \
    A006200184_153624_S4 \
    A006200184_153625_S5 \
    A006200184_153626_S6
    do
    umi_tools extract --bc-pattern=NNNNNNNNNNN --stdin=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R2_001.fastq.gz --read2-in=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R1_001.fastq.gz --stdout=${i}_add_barcode_R1.fastq.gz --read2-stdout
    umi_tools extract --bc-pattern=NNNNNNNNNNN --stdin=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R2_001.fastq.gz --read2-in=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R3_001.fastq.gz --stdout=${i}_add_barcode_R3.fastq.gz --read2-stdout
    /NVME/Software/QC/TrimGalore-0.6.5/trim_galore -j 30 -q 30 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -a2 AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT --fastqc --paired --output_dir clean_data ${i}_add_barcode_R1.fastq.gz ${i}_add_barcode_R3.fastq.gz
    done
    

Concatenated previous September data and new coverage data from October

Result in /home/linda/Data/all_data/

    i in 153621_S1 \
    153622_S2 \
    153623_S3 \
    153624_S4 \
    153625_S5 \
    153626_S6
    do
    cat /RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_September6/clean_data/A006200178_${i}*add_barcode_R1_val_1.fq.gz ../october/clean_data/A006200184*${i}*add_barcode_R1_val_1.fq.gz > $i.R1_val_1.fq.gz
    cat /RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_September6/clean_data/A006200178*${i}*add_barcode_R3_val_2.fq.gz ../october/clean_data/A006200184*${i}_add_barcode_R3_val_2.fq.gz > $i.R3_val_2.fq.gz
    done
- - - -
## 2. Alignment & Post-Alignment Processing <a name="Alignment"></a>
Mapping trimmed reads to the reference genome.
To look into script: cat /RAID/Data/linda/all_data/mapping.sh 
Before, runnning the command: 

bwa index /home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked
conda activate uni_tools
mkdir tmp
         
    for i in 153621_S1 \
    153622_S2 \
    153623_S3 \
    153624_S4 \
    153625_S5 \
    153626_S6
    do
    bwa mem -t 40 -R "@RG\tID:${i}\tSM:${i}\tLB:${i}\tPL:Illumina" /home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked ${i}.R1_val_1.fq.gz ${i}.R3_val_2.fq.gz > masked_mapped_data/${i}.sam
                #Run Aligntment with masked genome
    samtools view -bS mapped_data//${i}.sam > masked_mapped_data//${i}.bam
                #compress .sam into .bam
    samtools sort mapped_data/${i}.bam -o masked_mapped_data/${i}.sort.bam
                #sort mapped reads according to position in the genome
    samtools index masked_mapped_data/${i}.sort.bam
                #index sorted bams, creates .sort.bam.bai-file
    umi_tools dedup -I masked_mapped_data/${i}.sort.bam --output-stats=deduplicated --paired -S masked_mapped_data/${i}.sort.de.bam --temp-dir=tmp
                #remove all duplications 
    samtools index masked_mapped_data/${i}.sort.de.bam
                #index deduplicated bam
    done
- - - -
## 3. Variant Calling with GATK <a name="GATK"></a>

Creating a GVCF and VCF-File with GATK HaplotypeCaller and GenotypeGVFCs.

    ###software
    gatk=/NVME/Software/popgen/gatk-4.1.9.0/gatk
    ###data
    ref=/home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked
    bam1=$1
    bam2=$2
    gvcf1=$3
    gvcf2=$4
    mergedgvcf=$5
    vcf=$6
    
    ###build dict for genome
    /NVME/Software/popgen/gatk-4.1.9.0/gatk CreateSequenceDictionary -R /home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked -O Ppr.FINAL.dict
    
    ###call gvcf
    $gatk HaplotypeCaller \
            -R $ref \
            --emit-ref-confidence GVCF \
            -I $bam1 \
            -O $gvcf1
    
    ###call gvcf
    $gatk HaplotypeCaller \
            -R $ref \
            --emit-ref-confidence GVCF \
            -I $bam2 \
            -O $gvcf2
    
    ###merge them 
    $gatk CombineGVCFs \
        -R $ref \
        -V $gvcf1 \
        -V $gvcf2 \
        -O merged_gvcf/$mergedgvcf

    ###detect SNPs
    $gatk GenotypeGVCFs \
            -R $ref \
            -V $mergedgvcf \
            -O $vcf

    ###compress
    bgzip -f $vcf
    tabix -p vcf ${vcf}.gz
    
    # Filter out only SNPs from VCF 
    $gatk SelectVariants \
    -select-type SNP \
    -V ${vcf}.gz \
    -O ${vcf}.snp.gz
    
    # filter SNPs by parameters
    $gatk VariantFiltration \
    -V ${vcf}.snp.gz \
    --filter-expression "QD <2.0 || MQ <40.0 || FS >60.0 || SOR >3.0 || ReadPosRankSum < -8.0" \
    --filter-name "PASS" \
    -O ${vcf}.snp.f.gz
    
Executed the script with this: 

    sh VCFcalling.sh ../masked_mapping_data/153621_S1.sort.de.bam ../masked_mapping_data/153622_S2.sort.de.bam gvcf/s1.g.vcf gvcf/s2.g.vcf merged_vcf/s12.g.vcf merged_vcf/s12.vcf 
    sh VCFcalling.sh ../masked_mapping_data/153623_S3.sort.de.bam ../masked_mapping_data/153624_S4.sort.de.bam gvcf/s3.g.vcf gvcf/s4.g.vcf merged_vcf/s34.g.vcf merged_vcf/s34.vcf
    sh VCFcalling.sh ../masked_mapping_data/153625_S5.sort.de.bam ../masked_mapping_data/15366_S6.sort.de.bam gvcf/s5.g.vcf gvcf/s6.g.vcf merged_vcf/s56.g.vcf merged_vcf/s56.vcf
- - - -
## 4. Detect de novo mutations <a name="Mutations"> </a>

Filtered out 
i) heterozygous mother SNPs.
ii) all homozygous mother SNPs which had an allele depth under 60 the respective allele 
iii) all homozygous daugther SNPs where either the reference or alternate allele depth is under 60
iv) GQ under 60. Left were only Homozygous to Heterozygous SNPs with an allele depth over 60 for the supported allele and GQ over 60. 

cat /home/shangao/script/python/vcf_filter-same.3.py

I define of callable sites between 50% and 150% of the average, which would be [33.32;99.97]= [34;100], because the average coverage for all samples is 66.64715.

### i. Filtering DP <a name="DP"> </a>

Calculated the average genome coverage with bedtools

Sorted BAM-Files in /RAID/Data/linda/all-files/mapped_data
Script in RAID/Data/linda/all_data/mapped_data/genome_coverage/genome_coverage.sh


    for i in 153621_S1 \
    153622_S2 \
    153623_S3 \
    153624_S4 \
    153625_S5 \
    153626_S6
    do
    bedtools genomecov -ibam ../${i}.sort.de.bam -bga > ${i}_genome_coverage
    done

Then I calculated the average with awk.
Script in RAID/Data/linda/all_data/mapped_data/genome_coverage/mean_cov.sh 
And created a samtools flagfile for each sample.

Average genome coverage of each sample in average-genomecov.all

    Average coverage of S1= 66.297
    Average coverage of S2= 65.3743
    Average coverage of S3= 66.4849
    Average coverage of S4= 71.9713
    Average coverage of S5= 64.3218
    Average coverage of S6= 65.4336
    
Average genome coverage for all samples is 66.64715. 

### ii. Filtering GT <a name="GT"> </a>
### iii. Filtering GQ and PL <a name="GQ"> </a>
### iv. Filtering AD <a name="AD"> </a>

- - - -
## 5. Callable Genome estimation <a name="CG"> </a>

adding header to hf and gcov filtered data:

cat /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/filter/SNPs_after_gcov_filter/addheader.sh

    less /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters/s12.snp.f.vcf.gz | grep '#' > s12header | cat s12header /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters_gcov/s12.snp.f.gcov.vcf > s12.snp.hf.gcov.wheader.vcf

    less /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters/s34.snp.f.vcf.gz | grep '#' > s34header | cat s34header /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters_gcov/s34.snp.f.gcov.vcf > s34.snp.hf.gcov.wheader.vcf

    less /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters/s56.snp.f.vcf.gz | grep '#' > s56header | cat s56header /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters_gcov/s56.snp.f.gcov.vcf > s56.snp.hf.gcov.wheader.vcf

- - - -
## 6. Calculating the mutation rate <a name="Mutrate"> </a> 

The Mutation rate can be calculated as: 

Mutation counts / (2 x callable sites) = Mutation rate 

With the first calculations something between 1-2x10^-6 comes out which would be higher then for example spider mites. If Ppr has a lower mutation rate we would expect something under around 1*10^-9. 

What did I do differently to Linda? 
What could I have overseen? How many of them could be false-positives?
Is it possible to calculate the mutation rate differently? 

### b. Identifying Coding and Non-coding regions with existing gtf-file

extract coding regions from gtf-file.

    awk -v OFS='\t' '$3=="gene"{print$1,$4,$5}' /RAID/Data/mites/genomes/Ppr/version03/Ppr.gtf > coding_area_Ppr
    
    coding_area.sh

/RAID/Data/linda/all_data/mapped_data/genome_coverage/coding_area_gcov 
