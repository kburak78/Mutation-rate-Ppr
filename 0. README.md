# Estimation of Mutation Rate in Plathynothrus peltifer
- - - -

This repository encompasses all scripts of how I calculated the mutation rate in Plathynothrus peltifer.

The repository is structured as follows:
<details>
<summary> 1. [Sampling and Sequencing](#Sampling) </summary>
<p> [Sampling](#Sampling1) </p>
    </details> 

2. [Alignment & Post-Alignment Processing](#Alignment)

3. [Variant Calling with GATK](#GATK)

4. [Detect de novo mutations](#Mutations)

5. [Callable genome estimation](#CG)

6. [Calculating the mutation rate](#Mutrate)

You will also find two other files: 
'R Graphs' - the scripts to visualize my results 
'Ppr Eggs' - what I did for the additional data of two eggs 

- - - -

## 1. Sampling and Sequencing <a name="Sampling"></a>
### Sampling
The oribatid mites were sampled early June at the “Moorpfad” in Dahlem, Germany (50.389204, 6.568780).
- M6 -> S1 
- E6.2 -> S2
- M30 -> S3
- E30.7 -> S4
- M31 -> S5
- E31.6 -> S6
- E31. -> S7
- E31. -> S8
    
### 1.2 Sequncing 

The DNA was send to be sequenced with Illumina Next Generation Sequencing (NovaSeq6000) with 2 additional kits -the 'NEBNext Ultra II FS DNA Library Prep Kit for Illumina' and 'NEBNext Multiplex Oligos for Illumina (Unique Dual Index UMI Adaptors DNA Set 1)'.
FastaQ files provided by Cologne's Center for Genomics.

The average reading lenght was 151. 

The raw read is named like this and can be found in /RAID/Data/linda/Mother
153621_S1.R1_val_1.fq.gz
153621_S1.R3_val_2.fq.gz
153622_S2.R1_val_1.fq.gz
153622_S2.R3_val_2.fq.gz
153623_S3.R1_val_1.fq.gz
153623_S3.R3_val_2.fq.gz
153624_S4.R1_val_1.fq.gz
153624_S4.R3_val_2.fq.gz
153625_S5.R1_val_1.fq.gz
153625_S5.R3_val_2.fq.gz
153626_S6.R1_val_1.fq.gz
153626_S6.R3_val_2.fq.gz

Sequences provided by CCG in September and October. September ones went already through umi_tools and trimming in https://github.com/wintergoldcrest/umi_tools.

# 1.3 Umi tools and Trimming of October Data
Trimming Illumina adapters and Umi adapters from raw reads.
To look into the script: cat /RAID/Data/linda/october/test.sh
Don't forget to use execute "conda activate uni_tools" before running this script!

    for i in A006200184_153621_S1 \
    A006200184_153622_S2 \
    A006200184_153623_S3 \
    A006200184_153624_S4 \
    A006200184_153625_S5 \
    A006200184_153626_S6
    do
    umi_tools extract --bc-pattern=NNNNNNNNNNN --stdin=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R2_001.fastq.gz --read2-in=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R1_001.fastq.gz --stdout=${i}_add_barcode_R1.fastq.gz --read2-stdout
    umi_tools extract --bc-pattern=NNNNNNNNNNN --stdin=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R2_001.fastq.gz --read2-in=/RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_Oktober3/${i}_L002_R3_001.fastq.gz --stdout=${i}_add_barcode_R3.fastq.gz --read2-stdout
    /NVME/Software/QC/TrimGalore-0.6.5/trim_galore -j 30 -q 30 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -a2 AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT --fastqc --paired --output_dir clean_data ${i}_add_barcode_R1.fastq.gz ${i}_add_barcode_R3.fastq.gz
    done
    

## 1.4 Concatenated previous September data and new coverage data from October

Result in /home/linda/Data/all_data/

    i in 153621_S1 \
    153622_S2 \
    153623_S3 \
    153624_S4 \
    153625_S5 \
    153626_S6
    do
    cat /RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_September6/clean_data/A006200178_${i}*add_barcode_R1_val_1.fq.gz ../october/clean_data/A006200184*${i}*add_barcode_R1_val_1.fq.gz > $i.R1_val_1.fq.gz
    cat /RAID/Data/mites/reads/linda_umi/bastet.ccg.uni-koeln.de/downloads/jbast_JB03_September6/clean_data/A006200178*${i}*add_barcode_R3_val_2.fq.gz ../october/clean_data/A006200184*${i}_add_barcode_R3_val_2.fq.gz > $i.R3_val_2.fq.gz
    done

## 2. Alignment & Post-Alignment Processing <a name="Alignment"></a>
Mapping trimmed reads to the reference genome.
To look into script: cat /RAID/Data/linda/all_data/mapping.sh 
Do this before, runnning the command: 

bwa index /home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked
conda activate uni_tools
mkdir tmp

    for i in 153621_S1 \
    153622_S2 \
    153623_S3 \
    153624_S4 \
    153625_S5 \
    153626_S6
    do
    bwa mem -t 40 -R "@RG\tID:${i}\tSM:${i}\tLB:${i}\tPL:Illumina" /home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked ${i}.R1_val_1.fq.gz ${i}.R3_val_2.fq.gz > masked_mapped_data/${i}.sam
                #Run Aligntment with masked genome
    samtools view -bS mapped_data//${i}.sam > masked_mapped_data//${i}.bam
                #compress .sam into .bam
    samtools sort mapped_data/${i}.bam -o masked_mapped_data/${i}.sort.bam
                #sort mapped reads according to position in the genome
    samtools index masked_mapped_data/${i}.sort.bam
                #index sorted bams, creates .sort.bam.bai-file
    umi_tools dedup -I masked_mapped_data/${i}.sort.bam --output-stats=deduplicated --paired -S masked_mapped_data/${i}.sort.de.bam --temp-dir=tmp
                #remove all duplications 
    samtools index masked_mapped_data/${i}.sort.de.bam
                #index deduplicated bam
    done

## 3. Variant Calling with GATK <a name="GATK"></a>

Creating a GVCF and VCF-File with GATK HaplotypeCaller and GenotypeGVFCs.

    ###software
    gatk=/NVME/Software/popgen/gatk-4.1.9.0/gatk
    ###data
    ref=/home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked
    bam1=$1
    bam2=$2
    gvcf1=$3
    gvcf2=$4
    mergedgvcf=$5
    vcf=$6
    
    ###build dict for genome
    /NVME/Software/popgen/gatk-4.1.9.0/gatk CreateSequenceDictionary -R /home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.MAKER.masked -O Ppr.FINAL.dict
    
    ###call gvcf
    $gatk HaplotypeCaller \
            -R $ref \
            --emit-ref-confidence GVCF \
            -I $bam1 \
            -O $gvcf1
    
    ###call gvcf
    $gatk HaplotypeCaller \
            -R $ref \
            --emit-ref-confidence GVCF \
            -I $bam2 \
            -O $gvcf2
    
    ###merge them 
    $gatk CombineGVCFs \
        -R $ref \
        -V $gvcf1 \
        -V $gvcf2 \
        -O merged_gvcf/$mergedgvcf

    ###detect SNPs
    $gatk GenotypeGVCFs \
            -R $ref \
            -V $mergedgvcf \
            -O $vcf

    ###compress
    bgzip -f $vcf
    tabix -p vcf ${vcf}.gz
    
    # Filter out only SNPs from VCF 
    $gatk SelectVariants \
    -select-type SNP \
    -V ${vcf}.gz \
    -O ${vcf}.snp.gz
    
    # filter SNPs by parameters
    $gatk VariantFiltration \
    -V ${vcf}.snp.gz \
    --filter-expression "QD <2.0 || MQ <40.0 || FS >60.0 || SOR >3.0 || ReadPosRankSum < -8.0" \
    --filter-name "PASS" \
    -O ${vcf}.snp.f.gz
    
Executed the script with this: 

    sh VCFcalling.sh ../masked_mapping_data/153621_S1.sort.de.bam ../masked_mapping_data/153622_S2.sort.de.bam gvcf/s1.g.vcf gvcf/s2.g.vcf merged_vcf/s12.g.vcf merged_vcf/s12.vcf 
    sh VCFcalling.sh ../masked_mapping_data/153623_S3.sort.de.bam ../masked_mapping_data/153624_S4.sort.de.bam gvcf/s3.g.vcf gvcf/s4.g.vcf merged_vcf/s34.g.vcf merged_vcf/s34.vcf
    sh VCFcalling.sh ../masked_mapping_data/153625_S5.sort.de.bam ../masked_mapping_data/15366_S6.sort.de.bam gvcf/s5.g.vcf gvcf/s6.g.vcf merged_vcf/s56.g.vcf merged_vcf/s56.vcf

## 4.2 Calculated the average genome coverage with bedtools

Sorted BAM-Files in /RAID/Data/linda/all-files/mapped_data
Script in cat RAID/Data/linda/all_data/mapped_data/genome_coverage/genome_coverage.sh


    for i in 153621_S1 \
    153622_S2 \
    153623_S3 \
    153624_S4 \
    153625_S5 \
    153626_S6
    do
    bedtools genomecov -ibam ../${i}.sort.de.bam -bga > ${i}_genome_coverage
    done

Then I calculated the average with awk.
Script in RAID/Data/linda/all_data/mapped_data/genome_coverage/mean_cov.sh 
And created a samtools flagfile for each sample.

Average genome coverage of each sample in average-genomecov.all

    Average coverage of S1= 66.297
    Average coverage of S2= 65.3743
    Average coverage of S3= 66.4849
    Average coverage of S4= 71.9713
    Average coverage of S5= 64.3218
    Average coverage of S6= 65.4336
    
Average genome coverage for all samples is 66.64715. 

## 4.3 Identifying Coding and Non-coding regions with existing gtf-file

extract coding regions from gtf-file.

    awk -v OFS='\t' '$3=="gene"{print$1,$4,$5}' /RAID/Data/mites/genomes/Ppr/version03/Ppr.gtf > coding_area_Ppr
    
    
coding_area.sh

/RAID/Data/linda/all_data/mapped_data/genome_coverage/coding_area_gcov 




## 5. Filtering SNPs
Removed TE-Area: 

    for i in s12 s34 s56
    do
    #bedtools intersect -a ../$i.all.vcf.gz -b /home/shangao/Data/EDTA/Ppr/Ppr_instagrall/Ppr_instagrall.polished.fa.mod.EDTA.TEanno.gff3 -v > $i.all.removedTE.vcf
    python /home/shangao/script/python/vcf_filter-same.3.py -s $i.all.removedTE.vcf -o $i.all.removedTE_fDP_hap.vcf
    done

Filtered out 
i) heterozygous mother SNPs.
ii) all homozygous mother SNPs which had an allele depth under 60 the respective allele 
iii) all homozygous daugther SNPs where either the reference or alternate allele depth is under 60
iv) GQ under 60. Left were only Homozygous to Heterozygous SNPs with an allele depth over 60 for the supported allele and GQ over 60. 

cat /home/shangao/script/python/vcf_filter-same.3.py

    import sys
    import getopt
    import os
    def usage():
        print('''Useage: python script.py [option] [parameter]
        -s/input_file           input the lift file 
        -t/temp                 blasr_result
        -l/length                novel_seq
        -o/--output              the output results file
        -h/--help                show possible options''')
    #######################default
    opts, args = getopt.getopt(sys.argv[1:], "hs:t:o:l:",["help","sequence_file=","temp=","length","output="])  
    for op, value in opts:
        if op == "-s" or op=="--sequence_file":
            sequence_file = value
        elif op == "-o" or op =="--output": 
            output = value
        elif op == "-l" or op =="--length": 
            length = value
        elif op == "-t" or op =="--temp": 
            temp = value
        elif op == "-h" or op == "--help":
            usage()
            sys.exit(1)
    f1=open(sequence_file)
    #f2=open(temp)
    #f4=open(length,'w')
    f3=open(output,'w')
    total={}
    for l in f1.readlines():
            i=l.strip().split()
            if i[9].split(':')[0] == '0/0' or i[9].split(':')[0] == '0|0' or i[9].split(':')[0] == '1/1' or i[9].split(':')[0] == '1|1':
                if i[9].split(':')[0] == '0/0' or i[9].split(':')[0] == '0|0':
                    if int(i[9].split(':')[1].split(',')[0])<=60:
                        pass
                    elif int(i[9].split(':')[1].split(',')[1])!=0:
                        pass
                if i[9].split(':')[0] == '1/1' or i[9].split(':')[0] == '1|1':
                    if int(i[9].split(':')[1].split(',')[0])!=0:
                        pass
                    elif int(i[9].split(':')[1].split(',')[1])<=60:
                        pass
                elif i[10].split(':')[0] == '0/1' or i[10].split(':')[0] == '0|1' or i[10].split(':')[0] == '1|0':
                    if int(i[10].split(':')[1].split(',')[0])<=60:
                        pass
                    elif int(i[10].split(':')[1].split(',')[1])<=60:
                        pass
                    elif int(i[9].split(':')[3])<=90:
                        pass
                    elif int(i[10].split(':')[3])<=90:
                        pass
                    else:
                        f3.write(l)
                else:pass
    f1.close()
    #f2.close()
    f3.close()
    #f4.close()
    
    
    ## 9. Calculating the Average, Median and Variance of Coverage 

Calculated the median of each sample: 

    >cat /RAID/Data/linda/all_data/mapped_data/genome_coverage/genome_coverage.sh
    for i in 153621_S1 \
    153622_S2 \
    153623_S3 \
    153624_S4 \
    153625_S5 \
    153626_S6
    do
    awk '{print $4}' ${i}_genome_coverage | sort -n | awk ' { a[i++]=$1; } END { x=int((i+1)/2); print a[x-1]; }' >> median.txt
    done

    >cat /RAID/Data/linda/all_data/mapped_data/genome_coverage/median.txt 
    72
    71
    72
    78
    71
    72

## 5.2 Coverage range 

I define of callable sites between 50% and 150% of the average, which would be [33.32;99.97]= [34;100], because the average coverage for all samples is 66.64715.

## 5. calculating possible mutations 

adding header to hf and gcov filtered data:

cat /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/filter/SNPs_after_gcov_filter/addheader.sh

    less /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters/s12.snp.f.vcf.gz | grep '#' > s12header | cat s12header /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters_gcov/s12.snp.f.gcov.vcf > s12.snp.hf.gcov.wheader.vcf

    less /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters/s34.snp.f.vcf.gz | grep '#' > s34header | cat s34header /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters_gcov/s34.snp.f.gcov.vcf > s34.snp.hf.gcov.wheader.vcf

    less /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters/s56.snp.f.vcf.gz | grep '#' > s56header | cat s56header /RAID/Data/linda/Mother_Egg_Pairs_Ppr/vcf/merged_gvcf/SNPs_Hardfilters_gcov/s56.snp.f.gcov.vcf > s56.snp.hf.gcov.wheader.vcf
    
## 7. Calculating Mutation rate 

The Mutation rate can be calculated as: 

Mutation counts / (2 x callable sites) = Mutation rate 

With the first calculations something between 1-2x10^-6 comes out which would be higher then for example spider mites. If Ppr has a lower mutation rate we would expect something under around 1*10^-9. 

What did I do differently to Linda? 
What could I have overseen? How many of them could be false-positives?
Is it possible to calculate the mutation rate differently? 
